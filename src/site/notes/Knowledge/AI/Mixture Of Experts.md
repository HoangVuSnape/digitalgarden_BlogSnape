---
updated:
  - 2025-03-23T14:51:32+07:00
  - 2025-03-23T14:49:36+07:00
  - 2025-03-23T14:28:06+07:00
  - 2025-03-22T23:22:16+07:00
  - 2025-03-22T23:19:30+07:00
  - 2025-03-22T21:31:43+07:00
  - 2025-03-22T21:30:54+07:00
  - 2025-03-22T19:57:23+07:00
  - 2025-03-22T19:56:40+07:00
  - 2025-03-22T19:41:32+07:00
  - 2025-03-22T19:40:28+07:00
  - 2025-03-22T19:39:05+07:00
  - 2025-03-22T19:37:40+07:00
  - 2025-03-22T19:34:36+07:00
  - 2025-03-22T19:33:30+07:00
  - 2025-03-22T19:32:12+07:00
  - 2025-03-22T19:31:33+07:00
  - 2025-03-22T19:28:16+07:00
  - 2025-03-22T19:25:22+07:00
  - 2025-03-22T19:10:57+07:00
  - 2025-03-22T19:05:11+07:00
  - 2025-03-22T19:01:47+07:00
  - 2025-11-22 21:37:27
created: 2025-03-22T19:01:05
title: Mixture Of Experts
tags:
  - AI
  - nlp
append_modified_update: 
dg-publish: true
dg-home: 
dg-pinned: "false"
aliases: 
---
# References
- [BLog FB - MOE vs Transformer](https://www.facebook.com/groups/trituenhantao.io/permalink/2405703216462276/?rdid=bXiRYLqYr2qj7kpx#)
- [Blog hugging face Moe](https://huggingface.co/blog/moe?fbclid=IwZXh0bgNhZW0CMTAAAR2mQh_NiS4261QvWYKPlFKtvZodpjRcPeiYi_MIqomXcJtO78_43MoNf9s_aem_KDSf0SfA76nwo-TKrCsK6g)
- [IBM Moe](https://www.ibm.com/think/topics/mixture-of-experts?fbclid=IwZXh0bgNhZW0CMTAAAR0upo4EVgJoX9CD7f4xSZnhaBuOaVoLWGy4K3FoXr1gBt6VXs5GRUyqrDw_aem_85fNyvU5c3RPURDAbN4lng)
- [RAG technique](https://github.com/HoangVuSnape/RAG_Techniques)


# Key words
- Dense models - Sparsity , Moe Models
- Gshard 
- Router 


---

![](/img/user/assets/images/TransformerVsMoE.png)
# MoE: TÆ°Æ¡ng Lai Cá»§a MÃ´ HÃ¬nh AI Lá»›n?

## Giá»›i Thiá»‡u Vá» MoE

MoE (Mixture of Experts) lÃ  má»™t kiáº¿n trÃºc Ä‘á»™t phÃ¡ trong AI, giÃºp mÃ´ hÃ¬nh trá»Ÿ nÃªn linh hoáº¡t vÃ  hiá»‡u quáº£ hÆ¡n so vá»›i cÃ¡c mÃ´ hÃ¬nh dense truyá»n thá»‘ng. CÃ¡c mÃ´ hÃ¬nh MoE nhÆ° Mixtral 8x7B vÃ  DeepSeek MoE Ä‘ang chá»©ng minh ráº±ng chÃºng vá»«a nhanh, vá»«a cháº¥t lÆ°á»£ng!

## Lá»£i Ã­ch cá»§a MoE

### 1. Huáº¥n Luyá»‡n Hiá»‡u Quáº£

MoE giÃºp giáº£m thiá»ƒu tÃ i nguyÃªn tÃ­nh toÃ¡n trong giai Ä‘oáº¡n pretraining. Tuy nhiÃªn, quÃ¡ trÃ¬nh fine-tuning cÃ³ thá»ƒ gÃ¢y overfitting do cÃ¡c experts khÃ³ tá»•ng quÃ¡t hoÃ¡.

### 2. Suy Luáº­n SiÃªu Tá»‘c

DÃ¹ MoE cÃ³ ráº¥t nhiá»u tham sá»‘, nhÆ°ng chá»‰ má»™t pháº§n nhá» trong sá»‘ Ä‘Ã³ Ä‘Æ°á»£c kÃ­ch hoáº¡t khi suy luáº­n. Viá»‡c chá»n lá»c experts khi xá»­ lÃ½ giÃºp tÄƒng tá»‘c Ä‘á»™ so vá»›i mÃ´ hÃ¬nh dense tÆ°Æ¡ng Ä‘Æ°Æ¡ng.

## ThÃ¡ch Thá»©c Cá»§a MoE

### 1. YÃªu Cáº§u Bá»™ Nhá»› Cao

DÃ¹ chá»‰ kÃ­ch hoáº¡t má»™t pháº§n nhá» tham sá»‘ khi suy luáº­n, nhÆ°ng táº¥t cáº£ tham sá»‘ váº«n pháº£i Ä‘Æ°á»£c táº£i vÃ o RAM. VÃ­ dá»¥, Mixtral 8x7B dÃ¹ chá»‰ dÃ¹ng 13B tham sá»‘ khi suy luáº­n nhÆ°ng váº«n cáº§n Ä‘á»ƒ toÃ n bá»™ 47B tham sá»‘ trong RAM.

### 2. PhÃ¢n Phá»‘i Experts KhÃ´ng Äá»“ng Äá»u

- **Experts bá»‹ under-trained**: Má»™t sá»‘ experts bá»‹ láº¯m Ä‘Æ°á»ng, khÃ´ng Ä‘Æ°á»£c chá»n thÆ°á»ng xuyÃªn, dáº«n Ä‘áº¿n viá»‡c há»c khÃ´ng Ä‘á»“ng Ä‘á»u. Giáº£i phÃ¡p: ThÃªm nhiá»…u vÃ o router Ä‘á»ƒ tÄƒng tÃ­nh ngáº«u nhiÃªn khi chá»n experts.
- **Táº£i khÃ´ng cÃ¢n báº±ng**: Má»™t sá»‘ experts cÃ³ thá»ƒ bá»‹ quÃ¡ táº£i, trong khi nhá»¯ng experts khÃ¡c bá»‹ nháº¯c viá»‡c. Giáº£i phÃ¡p: Giá»›i háº¡n sá»‘ token má»—i expert cÃ³ thá»ƒ xá»­ lÃ½.

## Thá»±c Táº¿: Mixtral 8x7B vs. DeepSeek MoE

### **Mixtral 8x7B (Mistral AI)**

- **Tá»•ng sá»‘ tham sá»‘:** 47B, nhÆ°ng chá»‰ dÃ¹ng 13B khi suy luáº­n.
- **CÃ¡ch hoáº¡t Ä‘á»™ng:** Chá»‰ kÃ­ch hoáº¡t 2 experts trong 8 experts.
- **Hiá»‡u suáº¥t:** Nhanh hÆ¡n **6 láº§n** so vá»›i Llama 2 70B.
- **Tháº¿ máº¡nh:** ToÃ¡n há»c, láº­p trÃ¬nh, Ä‘a ngÃ´n ngá»¯.

### **DeepSeek MoE**

- **Chiáº¿n lÆ°á»£c:** Tá»«ng tá»± nhÆ° Mixtral, tá»‘i Æ°u hÃ³a viá»‡c chá»n experts.
- **MÃ´ hÃ¬nh:** DeepSeek 67B, cÃ³ hÃ ng chá»¥c tá»· tham sá»‘ nhÆ°ng ráº¥t tiáº¿t kiá»‡m tÃ i nguyÃªn.
- **á»¨ng dá»¥ng:** PhÃ¢n tÃ­ch dá»¯ liá»‡u, AI chatbot.

## Káº¿t Luáº­n

MoE mang láº¡i bÆ°á»›c nháº£y vá»t trong AI, káº¿t há»£p giá»¯a hiá»‡u suáº¥t vÃ  tÃ­nh linh hoáº¡t. Tuy nhiÃªn, nhá»¯ng thÃ¡ch thá»©c vá» bá»™ nhá»› vÃ  táº£i cÃ¢n báº±ng cáº§n Ä‘Æ°á»£c giáº£i quyáº¿t. CÃ¡c mÃ´ hÃ¬nh nhÆ° Mixtral 8x7B vÃ  DeepSeek MoE chá»©ng tá» ráº±ng MoE lÃ  hÆ°á»›ng Ä‘i Ä‘Ã¡ng chÃº Ã½ trong tÆ°Æ¡ng lai!



---
# 1. CÃ´ng thá»©c cÆ¡ báº£n cá»§a MoE Gating Network

MÃ´ hÃ¬nh Mixture of Experts (MoE) sá»­ dá»¥ng má»™t máº¡ng gating (G) Ä‘á»ƒ quyáº¿t Ä‘á»‹nh xem pháº§n nÃ o cá»§a Ä‘áº§u vÃ o sáº½ Ä‘Æ°á»£c gá»­i Ä‘áº¿n chuyÃªn gia nÃ o (E). CÃ´ng thá»©c chÃ­nh:
$$
y = \sum_{i=1}^{n} G(x)_i E_i(x)
$$

- \(G(x)\) lÃ  gating function, tráº£ vá» trá»ng sá»‘ cho tá»«ng chuyÃªn gia ( E<sub>i</sub>).
- \( E_i(x)\) lÃ  hÃ m cá»§a chuyÃªn gia thá»© \( i \) xá»­ lÃ½ Ä‘áº§u vÃ o \( x \).
- \(y\) lÃ  Ä‘áº§u ra cuá»‘i cÃ¹ng, Ä‘Æ°á»£c tÃ­nh báº±ng tá»•ng cÃ³ trá»ng sá»‘ cá»§a cÃ¡c Ä‘áº§u ra tá»« cÃ¡c chuyÃªn gia.

ğŸ‘‰ **Hiá»ƒu Ä‘Æ¡n giáº£n**: Gating network \( G(x) \) quyáº¿t Ä‘á»‹nh tá»· lá»‡ Ä‘áº§u vÃ o \( x \) Ä‘Æ°á»£c gá»­i Ä‘áº¿n cÃ¡c chuyÃªn gia \( E_i \).

---

# 2. Gating Function Truyá»n Thá»‘ng (Softmax)

Trong cÃ¡ch tiáº¿p cáº­n truyá»n thá»‘ng, gating function chá»‰ Ä‘Æ¡n giáº£n lÃ  má»™t máº¡ng nÆ¡-ron nhá» vá»›i hÃ m Softmax:

$$ G_{\sigma}(x) = \text{Softmax}(x \cdot W_g)$$

- \( W_g \) lÃ  trá»ng sá»‘ há»c Ä‘Æ°á»£c cá»§a máº¡ng gating.
- Softmax Ä‘áº£m báº£o tá»•ng cÃ¡c trá»ng sá»‘ \( G(x)_i \) cá»§a cÃ¡c chuyÃªn gia luÃ´n báº±ng 1, nghÄ©a lÃ  Ä‘áº§u vÃ o Ä‘Æ°á»£c chia tá»· lá»‡ há»£p lÃ½ giá»¯a cÃ¡c chuyÃªn gia.

ğŸ‘‰ **Hiá»ƒu Ä‘Æ¡n giáº£n**: Softmax giÃºp chá»n chuyÃªn gia nÃ o Ä‘Æ°á»£c kÃ­ch hoáº¡t vÃ  vá»›i tá»· lá»‡ bao nhiÃªu.

---

# 3. Noisy Top-k Gating (CÆ¡ cháº¿ chá»n lá»c k chuyÃªn gia)

Shazeer et al. Ä‘á» xuáº¥t má»™t phÆ°Æ¡ng phÃ¡p gating khÃ¡c gá»i lÃ  **Noisy Top-k Gating**, giÃºp lÃ m cho quÃ¡ trÃ¬nh chá»n chuyÃªn gia Ä‘a dáº¡ng hÆ¡n vÃ  giáº£m chi phÃ­ tÃ­nh toÃ¡n báº±ng cÃ¡ch chá»‰ chá»n k chuyÃªn gia cÃ³ giÃ¡ trá»‹ cao nháº¥t thay vÃ¬ dÃ¹ng táº¥t cáº£.

## BÆ°á»›c 1: ThÃªm nhiá»…u vÃ o tÃ­n hiá»‡u gating

$$
H(x)_i = (x \cdot W_g)_i + \text{StandardNormal()} \cdot \text{Softplus}((x \cdot W_{\text{noise}})_i)
$$

- W<sub>noise</sub> lÃ  trá»ng sá»‘ cá»§a thÃ nh pháº§n nhiá»…u, giÃºp tÄƒng tÃ­nh Ä‘a dáº¡ng trong quÃ¡ trÃ¬nh chá»n chuyÃªn gia.
- StandardNormal táº¡o nhiá»…u ngáº«u nhiÃªn theo phÃ¢n phá»‘i chuáº©n.
- Softplus Ä‘áº£m báº£o giÃ¡ trá»‹ nhiá»…u khÃ´ng bá»‹ Ã¢m quÃ¡ nhiá»u, giÃºp giá»¯ sá»± á»•n Ä‘á»‹nh.

ğŸ‘‰ **Hiá»ƒu Ä‘Æ¡n giáº£n**: ThÃªm má»™t lÆ°á»£ng nhiá»…u Ä‘iá»u chá»‰nh Ä‘Æ°á»£c vÃ o trá»ng sá»‘ gating Ä‘á»ƒ trÃ¡nh overfitting vÃ  giÃºp mÃ´ hÃ¬nh tá»•ng quÃ¡t hÃ³a tá»‘t hÆ¡n.

## BÆ°á»›c 2: Giá»¯ láº¡i chá»‰ \( k \) chuyÃªn gia cÃ³ trá»ng sá»‘ cao nháº¥t

$$
\text{KeepTopK}(v, k)_i =
\begin{cases} 
v_i & \text{náº¿u } v_i \text{ lÃ  1 trong } k \text{ giÃ¡ trá»‹ lá»›n nháº¥t cá»§a } v, \\
-\infty & \text{ngÆ°á»£c láº¡i}.
\end{cases}
$$

- Chá»‰ giá»¯ láº¡i \( k \) giÃ¡ trá»‹ lá»›n nháº¥t cá»§a \( H(x) \), Ä‘áº·t táº¥t cáº£ cÃ¡c giÃ¡ trá»‹ khÃ¡c thÃ nh \( -\infty \) (Ä‘á»ƒ Softmax sau nÃ y gáº§n nhÆ° báº±ng 0 cho chÃºng).
- Äiá»u nÃ y giÃºp giáº£m sá»‘ chuyÃªn gia hoáº¡t Ä‘á»™ng, tiáº¿t kiá»‡m tÃ­nh toÃ¡n.

ğŸ‘‰ **Hiá»ƒu Ä‘Æ¡n giáº£n**: Chá»‰ kÃ­ch hoáº¡t má»™t sá»‘ chuyÃªn gia tá»‘t nháº¥t thay vÃ¬ táº¥t cáº£.

## BÆ°á»›c 3: Ãp dá»¥ng Softmax chá»‰ trÃªn cÃ¡c giÃ¡ trá»‹ Ä‘Æ°á»£c giá»¯ láº¡i

$$
G(x) = \text{Softmax}(\text{KeepTopK}(H(x), k))
$$

- Sau khi chá»‰ giá»¯ láº¡i \( k \) chuyÃªn gia, ta chuáº©n hÃ³a láº¡i trá»ng sá»‘ báº±ng Softmax.
- Äiá»u nÃ y Ä‘áº£m báº£o tá»•ng trá»ng sá»‘ phÃ¢n bá»• giá»¯a cÃ¡c chuyÃªn gia váº«n há»£p lÃ½.

ğŸ‘‰ **Hiá»ƒu Ä‘Æ¡n giáº£n**: Tinh chá»‰nh trá»ng sá»‘ cuá»‘i cÃ¹ng báº±ng Softmax sau khi Ä‘Ã£ lá»c ra cÃ¡c chuyÃªn gia tá»‘t nháº¥t.

---

# 4. Lá»£i Ã­ch cá»§a Noisy Top-k Gating

âœ… **Giáº£m chi phÃ­ tÃ­nh toÃ¡n**: VÃ¬ chá»‰ cÃ³ \( k \) chuyÃªn gia Ä‘Æ°á»£c kÃ­ch hoáº¡t thay vÃ¬ táº¥t cáº£.  
âœ… **Cáº£i thiá»‡n tÃ­nh Ä‘a dáº¡ng**: Viá»‡c thÃªm nhiá»…u giÃºp mÃ´ hÃ¬nh há»c cÃ¡ch chá»n chuyÃªn gia má»™t cÃ¡ch linh hoáº¡t hÆ¡n.  
âœ… **TÄƒng hiá»‡u suáº¥t há»c**: Ban Ä‘áº§u, ngÆ°á»i ta nghÄ© ráº±ng chá»n 1 chuyÃªn gia duy nháº¥t lÃ  Ä‘á»§, nhÆ°ng thá»±c táº¿ cáº§n Ã­t nháº¥t 2 chuyÃªn gia Ä‘á»ƒ máº¡ng cÃ³ thá»ƒ há»c cÃ¡ch phÃ¢n loáº¡i Ä‘áº§u vÃ o há»£p lÃ½.  

ğŸš€ **TÃ³m láº¡i**:  
- Máº¡ng Gating giÃºp quyáº¿t Ä‘á»‹nh dá»¯ liá»‡u nÃ o sáº½ Ä‘Æ°á»£c xá»­ lÃ½ bá»Ÿi chuyÃªn gia nÃ o.  
- CÃ¡ch Ä‘Æ¡n giáº£n nháº¥t lÃ 
---

# Evaluation

![](/img/user/assets/images/MOE_1.png)

![](/img/user/assets/images/MOE_2.png)


![](/img/user/assets/images/MOE_3.png)

![](/img/user/assets/images/MOE_4.png)

![](/img/user/assets/images/MOE_5.png)